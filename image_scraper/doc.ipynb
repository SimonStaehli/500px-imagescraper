{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cebbf02-e38b-4fca-a56c-663e983cd241",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Code Documentation of ImageScraper\n",
    "\n",
    "## Description of the Idea\n",
    "\n",
    "The imagescraper I have created is to scrape images from the website https://www.500px.com/. This website is a platform for photographers to share their work with other photographers. On this webpage you can find a lot of high quality images in differnt image classes provided by each photographers. As I am a user and member of this website too and share images as well from time to time, I wanted to create a scraper to scrape images with their respective classes from the website. Furthermore the idea behind the scraping and their image classes is to create an image classification model for photography, which could potentially used for different websites to classify the uploaded images.\n",
    "\n",
    "## Getting Started:\n",
    "\n",
    "This part describes in which ways the imagescraper can be used to achieve your scraping goals. There are actually two different ways to scrape from the webpage:\n",
    "\n",
    "1. Call the ImageCrawler500 class and its crawl method to scrape a certain amount of different picture from each image class.\n",
    "2. It is possible to do an image streaming, which one could also call a mirror, if you put in a close density of stream times as class attribute.\n",
    "\n",
    "### Method 1: ImageCrawler500\n",
    "\n",
    "Crawl images from the website with a fixed amount of images per class. It is possible to make use of the script `crawler_exe.py`. Parameters with this script need to be adjusted as well before the script is started.\n",
    "\n",
    "#### Usage Procedure with class import:\n",
    "- Initiate class with the relevant paramters:\n",
    "    - path to your selenium webdriver. My Webdrier was chromedriver given in the path.\n",
    "    - Then chose the amount of images you want from each class.\n",
    "    - then choose popularity ranking, which are listed on the website.\n",
    "- call method crawl() to start the process.\n",
    "- After all image sources where extracted the picture will be stored in the folder structure with the respective image class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52d40e-096f-4e83-9296-7d81c597fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import class ImageCrawler500\n",
    "from imagescraper500 import ImageCrawler500\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef45c54d-f337-49ec-ae6e-4ca6b6dff552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate class\n",
    "crawler = ImageCrawler500(webdriver=webdriver.Chrome('./src/chromedriver.exe'),\n",
    "                          amount_per_class=2, \n",
    "                          popularity_ranking='popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8329905-8b3c-41a0-8edd-07e0ac11bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start process\n",
    "crawler.crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5948c059-c12b-4b95-9606-561d8d089dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_count_in_folder = crawler.count_collected_images(print_count=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457792b1-8989-430c-91d5-65309fa4f838",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Method 2: ImageStream500\n",
    "\n",
    "The second method is to make an image stream of a particular image class. The stream makes it possible to get all new images within a class or to scrape an amount of images at a defined time. Therefore two scripts were created in the folder run. `stream_exe.py`, `stream_exe_no_scheduler.py`\n",
    "\n",
    "`stream_exe.py` is meant to run with the program scheduler used in windows for example. The other script runs by itself at the times defined within the script.\n",
    "\n",
    "#### Usage Procedure with class import:\n",
    "- Initiate class with the relevant paramters:\n",
    "    - Initiate a selenium webdriver object\n",
    "    - Then chose the amount of images you want from each class.\n",
    "    - then choose popularity ranking, which are listed on the website.\n",
    "- call method stream() to start the process.\n",
    "- After all image sources where extracted the picture will be stored in the folder structure with the respective image class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ac7ffc-b4c9-4083-b4ee-b261f4406f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imagescraper500 import ImageStream500\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c235cf75-79fb-46fe-8c23-814d040de8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamer = ImageStream500(webdriver=webdriver.Chrome('./src/chromedriver.exe'), \n",
    "                          popularity='fresh', iter_sampling_rate=10, batchsize=15, \n",
    "                          stream_time=5, image_folder_path='./images'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ecc24de-4acb-43e2-abb5-af4b7bacbedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Extracted 7 more images successfully in Iteration.\n",
      "| Extracted 8 more images successfully in Iteration.\n",
      "| Extracted 8 more images successfully in Iteration.\n",
      "| Extracted 9 more images successfully in Iteration.\n",
      "| Extracted 10 more images successfully in Iteration.\n",
      "| Extracted 11 more images successfully in Iteration.\n",
      "| Extracted 12 more images successfully in Iteration.\n",
      "| Extracted 14 more images successfully in Iteration.\n",
      "| Extracted 16 more images successfully in Iteration.\n",
      "| Extracted 17 more images successfully in Iteration.\n",
      "| Extracted 18 more images successfully in Iteration.\n",
      "| Extracted 19 more images successfully in Iteration.\n",
      "| Extracted 23 more images successfully in Iteration.\n",
      "| Starting download of all images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:21<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Saved Image Batch to folder.\n",
      "| Extracted 4 more images successfully in Iteration.\n",
      "| Extracted 9 more images successfully in Iteration.\n",
      "| Starting download of all images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:08<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Saved Last Image Batch to folder.\n",
      "| Stream Time of 5 min over.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<imagescraper500.ImageStream500 at 0x1f07d1bc490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streamer.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf87de41-857a-4afd-b71e-6283211b3bcc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Relevance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be218e6c-da5b-4277-9da5-c3f3b0fe52f7",
   "metadata": {},
   "source": [
    "I think this project I can use this scraper for the module Deep Learning (dpl), in which I probably need a lot of higher quality image, which this website is dedicated for."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
